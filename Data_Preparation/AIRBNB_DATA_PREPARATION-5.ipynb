{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67550ea3-f7d1-4314-9f04-fb56094ba6c9",
   "metadata": {
    "collapsed": false,
    "name": "cell7"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8342f6-e894-4f86-bd60-cf76bdaf367f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Connect to Snowflake\n",
    "\n",
    "# Query data\n",
    "query = \"SELECT room_type, property_type, accommodates, bathrooms bedrooms, beds, price, minimum_nights, maximum_nights, availability_365, host_is_superhost, host_listings_count, instant_bookable, review_scores_rating, number_of_reviews, reviews_per_month, latitude, longtitude FROM LISTINGS_NYC;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699730e-478b-49b0-a47e-d10e0edd885a",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "# 描述统计（数值型）\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5ab1a-a773-41a3-83a4-8cb124a27431",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c0f99-abad-4c91-9824-4177fa49d204",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9534d94-8348-4a12-932b-914e00e73729",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "### Efficient basic processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e6070-d037-47aa-8316-9ddddb7c8ed9",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "-- SQL Cell\n",
    "CREATE OR REPLACE TEMP TABLE cleaned_listings AS\n",
    "SELECT\n",
    "  id,\n",
    "  TRY_TO_NUMBER(REPLACE(REPLACE(price, '$', ''), ',', '')) AS price,\n",
    "  COALESCE(host_is_superhost, 'f') = 't' AS host_is_superhost,\n",
    "  instant_bookable = 't' AS instant_bookable,\n",
    "  COALESCE(host_listings_count, 0) AS host_listings_count,\n",
    "  LN(1 + COALESCE(host_listings_count, 0)) AS host_listings_count_log,\n",
    "  bedrooms,\n",
    "  beds,\n",
    "  accommodates,\n",
    "  room_type,\n",
    "  NEIGHBOURHOOD_GROUP_CLEANSED,\n",
    "  property_type,\n",
    "  minimum_nights,\n",
    "  maximum_nights,\n",
    "  availability_365,\n",
    "  COALESCE(TRY_TO_NUMBER(reviews_per_month), 0) AS reviews_per_month,\n",
    "  latitude,\n",
    "  longtitude\n",
    "FROM LISTINGS_NYC\n",
    "WHERE minimum_nights <= 60 AND maximum_nights <= 365;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5bfef-f761-4373-bcd6-b0c8a5c1431b",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "### Initial Data Cleaning Summary\n",
    "We performed initial structured data cleaning in SQL to efficiently filter, convert, and preprocess fields close to the data source, reserving more complex imputations and modeling tasks for Python.\n",
    "\n",
    "- `price`: Removed `$` and `,` characters and converted the result to a numeric value using `TRY_TO_NUMBER`.\n",
    "\n",
    "- `host_is_superhost`: Replaced nulls with `'f'` (false) and converted `'t'/'f'` values to Boolean (`TRUE` if superhost).\n",
    "\n",
    "- `instant_bookable`: Converted `'t'/'f'` values to Boolean for easier downstream processing.\n",
    "\n",
    "- `host_listings_count`: Replaced missing values with `0` and created a log-transformed version `host_listings_count_log` to reduce skewness.\n",
    "\n",
    "- `bedrooms` and `beds`: Left as-is for now. Missing values will be handled in Python using more advanced logic (e.g., based on nearby listings).\n",
    "\n",
    "- `minimum_nights`, `maximum_nights`: Retained, but we filtered out extreme values by restricting to `≤ 60` and `≤ 365` respectively.\n",
    "\n",
    "- `reviews_per_month`: Converted to numeric using `TRY_TO_NUMBER`, filled nulls with 0.\n",
    "\n",
    "- All other features (`accommodates`, `room_type`, `property_type`, `number_of_reviews`, `latitude`, `longtitude`) were kept as-is for downstream feature engineering and modeling.\n",
    "\n",
    "This table serves as the cleaned base for further processing in Python, where we will handle missing values and construct derived features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b303b1-3925-4f71-bec7-02b32076a161",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "### \"BEDROOMS\" and \"BEDS\" columns Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ec22c-1bb7-4ca6-a162-143dc56d3fb0",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "df = session.table(\"cleaned_listings\").to_pandas()\n",
    "\n",
    "for col in ['BEDROOMS', 'BEDS', 'PRICE']:\n",
    "    df[col] = df.groupby(['NEIGHBOURHOOD_GROUP_CLEANSED', 'ROOM_TYPE'])[col]\\\n",
    "                .transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "df = df[~((df['BEDROOMS'] > 0) & (df['BEDS'] == 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b594b5-0599-4ffb-a4ae-19474bd3eef2",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": [
    "### Missing Data Imputation Summary\n",
    "1. We impute bedrooms, beds, and price by grouping on NEIGHBOURHOOD_GROUP_CLEANSED and room_type, using the group-wise median, with a fallback to the global median when group data is insufficient.\n",
    "2. We found 222 listings (3.32%) where bedrooms > 0 but beds == 0, which is logically inconsistent. These were likely due to data entry errors. To ensure data quality, we removed these records from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96511816-d583-4904-afd0-a96f58210bb3",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "### Transformation and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81cfa1-1bff-4ada-b4e6-95b45e5fc7f2",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 检查价格分布\n",
    "# sns.histplot(df['PRICE'], bins=100)\n",
    "# plt.title(\"Price Distribution\")\n",
    "# plt.show()\n",
    "\n",
    "# # 检查评论数分布\n",
    "# sns.histplot(df['NUMBER_OF_REVIEWS'], bins=100)\n",
    "# plt.title(\"Number of Reviews Distribution\")\n",
    "# plt.show()\n",
    "\n",
    "# sns.histplot(df['REVIEWS_PER_MONTH'].dropna(), bins=50)\n",
    "# plt.title(\"Distribution of NUMBER_OF_REVIEWS_PER_MONTH\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873fa4b-8b22-4586-b850-515fd370c697",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# columns_to_check = ['ACCOMMODATES', 'BEDROOMS', 'BEDS', 'AVAILABILITY_365', 'HOST_LISTINGS_COUNT']\n",
    "\n",
    "# for col in columns_to_check:\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     sns.histplot(df[col].dropna(), bins=50, kde=False)\n",
    "#     plt.title(f\"Distribution of {col}\")\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6789ca-394a-4a56-9118-3286a898cd3f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. LOG_PRICE：处理价格偏态\n",
    "df['LOG_PRICE'] = np.log1p(df['PRICE'])\n",
    "\n",
    "# 2. LOG_REVIEWS_PER_MONTH：替代 NUMBER_OF_REVIEWS，处理偏态\n",
    "df['LOG_REVIEWS_PER_MONTH'] = np.log1p(df['REVIEWS_PER_MONTH'])\n",
    "\n",
    "# 3. LISTING_DENSITY：单位可出租天数上的活跃程度\n",
    "df['LISTING_DENSITY'] = df['REVIEWS_PER_MONTH'] / (df['AVAILABILITY_365'] + 1)  # 避免除以 0\n",
    "\n",
    "# 4. BEDROOM_BED_RATIO：结构合理性指标\n",
    "df['BEDROOM_BED_RATIO'] = df['BEDROOMS'] / (df['BEDS'] + 1)  # 避免除以 0\n",
    "\n",
    "# 必做\n",
    "df['LOG_HOST_LISTINGS_COUNT'] = np.log1p(df['HOST_LISTINGS_COUNT'])\n",
    "\n",
    "# 可选（建议保留做对比）\n",
    "df['LOG_AVAILABILITY_365'] = np.log1p(df['AVAILABILITY_365'])\n",
    "\n",
    "df = pd.get_dummies(df, columns=['ROOM_TYPE', 'PROPERTY_TYPE', 'NEIGHBOURHOOD_GROUP_CLEANSED'], drop_first=True)\n",
    "\n",
    "# 选取用于建模的特征列\n",
    "features = ['LOG_PRICE', 'ACCOMMODATES', 'BEDROOMS', 'BEDS', 'LOG_AVAILABILITY_365',\n",
    "    'LOG_REVIEWS_PER_MONTH', 'LISTING_DENSITY', 'LOG_HOST_LISTINGS_COUNT', 'BEDROOM_BED_RATIO',\n",
    "] + [col for col in df.columns if 'ROOM_TYPE_' in col or 'PROPERTY_TYPE_' in col]\n",
    "\n",
    "X = df[features].copy()\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ed06f-f628-44d7-aba8-dff364308c47",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "### Feature Transformation Summary\n",
    "\n",
    "In this section, we transformed key features to reduce skewness, normalize scales, and engineer meaningful ratios for downstream modeling.\n",
    "\n",
    "#### Applied Transformations:\n",
    "- **LOG_PRICE**: Applied `log1p(PRICE)` to reduce skewness in nightly price distribution.\n",
    "- **LOG_REVIEWS_PER_MONTH**: Used `log1p(NUMBER_OF_REVIEWS_PER_MONTH)` instead of `NUMBER_OF_REVIEWS`, which contained only zeros.\n",
    "- **LISTING_DENSITY**: Computed as `NUMBER_OF_REVIEWS_PER_MONTH / (AVAILABILITY_365 + 1)` to normalize review activity by listing availability.\n",
    "- **BEDROOM_BED_RATIO**: Defined as `BEDROOMS / (BEDS + 1)` to detect configuration inconsistencies (e.g., listings with many bedrooms but few or no beds).\n",
    "- **LOG_HOST_LISTINGS_COUNT**: Applied `log1p(HOST_LISTINGS_COUNT)` due to extreme right-skew in host portfolio sizes.\n",
    "- **LOG_AVAILABILITY_365** (optional): Captures variation in listing availability, which showed a bimodal distribution (0 and 365 were common extremes).\n",
    "\n",
    "#### No Transformation Needed:\n",
    "- **ACCOMMODATES**, **BEDROOMS**, and **BEDS** are low-range discrete count features with relatively stable distributions, and were left untransformed.\n",
    "\n",
    "These transformations help improve model interpretability, reduce the influence of extreme values, and support more effective clustering and anomaly detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7985c3-4b15-4fdc-800f-8bc0a881cb1f",
   "metadata": {
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bdea4-9ace-4d0f-9927-1ba348012416",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36e42c-e66e-41bb-a326-d09047ff857b",
   "metadata": {
    "collapsed": false,
    "name": "cell16"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05056832-e2ce-4086-9ca0-799a4a89a7b4",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#可选：先降维到 10 维以内\n",
    "pca = PCA(n_components=10)\n",
    "X_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 运行 DBSCAN（参数可调试）\n",
    "dbscan = DBSCAN(eps=1.5, min_samples=10)\n",
    "df['CLUSTER_LABEL'] = dbscan.fit_predict(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f76ea-00af-45b5-8d07-98fde0638c74",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619d1c4-3b17-4a4d-8026-4a94ca1d807d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "print(df['CLUSTER_LABEL'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7000a47-58f9-4493-97d9-68dfedc6d115",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "# 降到 2 维\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "# 添加到 df\n",
    "df['PCA1'] = X_reduced[:, 0]\n",
    "df['PCA2'] = X_reduced[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023666f6-ac5f-4d00-9c6f-57f84ff384f1",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "palette = sns.color_palette('tab20', n_colors=df['CLUSTER_LABEL'].nunique())\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='PCA1',\n",
    "    y='PCA2',\n",
    "    hue='CLUSTER_LABEL',\n",
    "    palette=palette,\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "plt.title('DBSCAN Clustering Result (PCA Projection)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b04f00a-f376-4e95-9837-5cc108191663",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": [
    "### Initial Clustering Summary\n",
    "\n",
    "In this stage, we performed unsupervised clustering on Airbnb listings data to uncover natural groupings among listings:\n",
    "- **Dimensionality Reduction**: We applied PCA to reduce the feature space to 10 dimensions to improve DBSCAN performance and enable visualization.\n",
    "- **Clustering with DBSCAN**:\n",
    "  - Used `DBSCAN` to discover density-based clusters without pre-specifying the number of clusters.\n",
    "  - Identified multiple meaningful clusters along with a group of noise points (`CLUSTER_LABEL = -1`).\n",
    "- **Visualization**: Plotted PCA-projected cluster assignments to evaluate separation quality and interpretability.\n",
    "- **Goal**: This clustering provides a foundation for downstream **causal analysis**, allowing us to investigate **why listings fall into specific clusters** based on their attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7534ce-bb42-4ce8-842a-5da7b0437b32",
   "metadata": {
    "collapsed": false,
    "name": "cell25"
   },
   "source": [
    "### Use causal inference to identify cluster label determinants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3979d-9bd4-43f3-977f-7f45da59b0ae",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 用你之前选择的特征（注意：全部大写）\n",
    "features = ['LOG_PRICE', 'ACCOMMODATES', 'BEDROOMS', 'BEDS', 'LOG_AVAILABILITY_365',\n",
    "    'LOG_REVIEWS_PER_MONTH', 'LISTING_DENSITY', 'LOG_HOST_LISTINGS_COUNT', 'BEDROOM_BED_RATIO',\n",
    "] + [col for col in df.columns if 'ROOM_TYPE_' in col or 'PROPERTY_TYPE_' in col]\n",
    "\n",
    "X = df[features]\n",
    "y = df['CLUSTER_LABEL']\n",
    "\n",
    "# 拆分训练测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187ff49-44d3-4b90-ad09-cf2bf58b5d91",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", rf.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b18b2-9efd-4a82-b0a4-83b2cddf0752",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# 创建 SHAP 解释器（TreeExplainer 专为树模型设计）\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 全局特征重要性图（支持多分类）\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38c8cc-e8ea-4cbb-9934-84cc185a3ace",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- 初始变量 ----\n",
    "X_all = df[features].copy()\n",
    "loop_history = []\n",
    "max_loops = 5\n",
    "early_stop_threshold = 0.01  # 当指标改善小于1%时停止\n",
    "min_features = 3  # 最少要保留多少个特征\n",
    "\n",
    "# 初始聚类标签\n",
    "current_labels = df[\"CLUSTER_LABEL\"].values\n",
    "\n",
    "# ---- LOOP 开始 ----\n",
    "for loop in range(max_loops):\n",
    "    print(f\"\\n====== LOOP {loop+1} ======\")\n",
    "\n",
    "    # 1. 特征重要性分析（随机森林）\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_all, current_labels)\n",
    "    importances = rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X_all.columns,\n",
    "        'importance': importances\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # 2. 选择前 N 个重要特征\n",
    "    n_keep = max(min_features, int(len(X_all.columns) * 0.4))  # 只保留前40%重要的特征\n",
    "    top_features = importance_df['feature'].iloc[:n_keep].tolist()\n",
    "    X_selected = X_all[top_features]\n",
    "\n",
    "    # 3. 标准化\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "    # 4. 聚类\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    new_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "    # 如果聚不到簇或只聚出1类，跳出循环\n",
    "    n_clusters = len(set(new_labels)) - (1 if -1 in new_labels else 0)\n",
    "    if n_clusters <= 1:\n",
    "        print(\"⚠️ 聚类簇数过少，跳出循环。\")\n",
    "        break\n",
    "\n",
    "    # 5. 计算聚类评估指标\n",
    "    sil_score = silhouette_score(X_scaled, new_labels)\n",
    "    ch_score = calinski_harabasz_score(X_scaled, new_labels)\n",
    "    db_score = davies_bouldin_score(X_scaled, new_labels)\n",
    "\n",
    "    print(f\"特征数量：{len(top_features)}\")\n",
    "    print(f\"聚类数：{n_clusters}\")\n",
    "    print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "    print(f\"Calinski-Harabasz: {ch_score:.2f}\")\n",
    "    print(f\"Davies-Bouldin: {db_score:.4f}\")\n",
    "\n",
    "    # 6. 保存历史结果\n",
    "    loop_history.append({\n",
    "        'loop': loop + 1,\n",
    "        'features': top_features,\n",
    "        'n_clusters': n_clusters,\n",
    "        'silhouette': sil_score,\n",
    "        'ch': ch_score,\n",
    "        'db': db_score,\n",
    "        'labels': new_labels\n",
    "    })\n",
    "\n",
    "    # 7. 判断是否 Early Stop\n",
    "    if loop >= 1:\n",
    "        prev = loop_history[-2]\n",
    "        curr = loop_history[-1]\n",
    "        sil_change = abs(curr['silhouette'] - prev['silhouette']) / (prev['silhouette'] + 1e-6)\n",
    "        if sil_change < early_stop_threshold:\n",
    "            print(\"✅ Silhouette 提升不足，Early Stop。\")\n",
    "            break\n",
    "\n",
    "    # 8. 更新标签进入下一轮\n",
    "    current_labels = new_labels\n",
    "    X_all = df[top_features].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f85753-9895-4cd8-8aed-86221fb7eb89",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sil_vals = [d['silhouette'] for d in loop_history]\n",
    "plt.plot(range(1, len(sil_vals)+1), sil_vals, marker='o')\n",
    "plt.title('Silhouette Score Across Loops')\n",
    "plt.xlabel('Loop')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8632959-8859-4389-91f8-f2c48e7e3136",
   "metadata": {
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_all)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=current_labels, cmap='tab10', s=10, alpha=0.8)\n",
    "plt.title(\"Final Cluster Visualization (t-SNE)\")\n",
    "plt.xlabel(\"t-SNE Dim 1\")\n",
    "plt.ylabel(\"t-SNE Dim 2\")\n",
    "plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e3a30-28e3-45d0-a824-2a2757e91976",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "df['FINAL_CLUSTER'] = loop_history[-1]['labels']\n",
    "df['FINAL_CLUSTER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8855-33cd-4001-a095-aae6012fa07a",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell47"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da1134-5b04-495a-b332-91c8c4c26724",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell46"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a895a-af30-4ae9-99ba-78ded1b26981",
   "metadata": {
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa02a0-ae5a-4e05-8fe7-264e5ac52ac3",
   "metadata": {
    "language": "python",
    "name": "cell44"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2bb029-83fb-476a-a7e5-df90036674e0",
   "metadata": {
    "collapsed": false,
    "name": "cell35"
   },
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae11d5a-bdf1-42bc-a4ec-7e7e691155d5",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from collections import Counter\n",
    "\n",
    "def classify_listing_from_raw_input(user_input_raw, top_features, scaler, X_scaled, cluster_labels, rare_threshold=0.04):\n",
    "    \"\"\"\n",
    "    Classify a new Airbnb listing from raw user input using final DBSCAN clustering.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Raw feature cleaning and engineering\n",
    "    df_input = pd.DataFrame([user_input_raw])\n",
    "\n",
    "    # Fill missing or derived-friendly defaults\n",
    "    df_input[\"PRICE\"] = df_input[\"PRICE\"].astype(float)\n",
    "    df_input[\"REVIEWS_PER_MONTH\"] = df_input[\"REVIEWS_PER_MONTH\"].astype(float)\n",
    "    df_input[\"HOST_LISTINGS_COUNT\"] = df_input[\"HOST_LISTINGS_COUNT\"].astype(float)\n",
    "    df_input[\"AVAILABILITY_365\"] = df_input[\"AVAILABILITY_365\"].astype(float)\n",
    "    df_input[\"BEDROOMS\"] = df_input[\"BEDROOMS\"].fillna(1)\n",
    "    df_input[\"BEDS\"] = df_input[\"BEDS\"].fillna(1)\n",
    "\n",
    "    # Feature derivation\n",
    "    df_input[\"LOG_PRICE\"] = np.log1p(df_input[\"PRICE\"])\n",
    "    df_input[\"LOG_REVIEWS_PER_MONTH\"] = np.log1p(df_input[\"REVIEWS_PER_MONTH\"])\n",
    "    df_input[\"LOG_HOST_LISTINGS_COUNT\"] = np.log1p(df_input[\"HOST_LISTINGS_COUNT\"])\n",
    "    df_input[\"LOG_AVAILABILITY_365\"] = np.log1p(df_input[\"AVAILABILITY_365\"])\n",
    "    df_input[\"LISTING_DENSITY\"] = df_input[\"REVIEWS_PER_MONTH\"] / (df_input[\"AVAILABILITY_365\"] + 1)\n",
    "    df_input[\"BEDROOM_BED_RATIO\"] = df_input[\"BEDROOMS\"] / (df_input[\"BEDS\"] + 1)\n",
    "\n",
    "    # Step 2: One-hot encode ROOM_TYPE and PROPERTY_TYPE\n",
    "    room_dummies = pd.get_dummies(df_input[\"ROOM_TYPE\"], prefix=\"ROOM_TYPE\")\n",
    "    prop_dummies = pd.get_dummies(df_input[\"PROPERTY_TYPE\"], prefix=\"PROPERTY_TYPE\")\n",
    "    df_input = pd.concat([df_input, room_dummies, prop_dummies], axis=1)\n",
    "\n",
    "    # Step 3: Match top_features\n",
    "    for col in top_features:\n",
    "        if col not in df_input.columns:\n",
    "            df_input[col] = 0  # Fill missing one-hot columns with 0\n",
    "\n",
    "    X_user = df_input[top_features]\n",
    "    X_user_scaled = scaler.transform(X_user)\n",
    "\n",
    "    # Step 4: Compare to cluster centers\n",
    "    cluster_sizes = Counter(cluster_labels)\n",
    "    cluster_centers = {}\n",
    "    cluster_distances = {}\n",
    "\n",
    "    for label in set(cluster_labels):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        cluster_points = X_scaled[cluster_labels == label]\n",
    "        center = cluster_points.mean(axis=0)\n",
    "        cluster_centers[label] = center\n",
    "        cluster_distances[label] = euclidean_distances(X_user_scaled, center.reshape(1, -1))[0][0]\n",
    "\n",
    "    if not cluster_distances:\n",
    "        return {\"type\": \"anomaly\", \"reason\": \"No clusters available.\"}\n",
    "\n",
    "    closest_cluster = min(cluster_distances, key=cluster_distances.get)\n",
    "    closest_distance = cluster_distances[closest_cluster]\n",
    "    cluster_ratio = cluster_sizes[closest_cluster] / len(cluster_labels)\n",
    "\n",
    "    # 95% cutoff in this cluster\n",
    "    own_distances = euclidean_distances(X_scaled[cluster_labels == closest_cluster], cluster_centers[closest_cluster].reshape(1, -1))\n",
    "    abnormal_cutoff = np.percentile(own_distances, 95)\n",
    "\n",
    "    if closest_distance > abnormal_cutoff:\n",
    "        label_type = \"anomaly\"\n",
    "    elif cluster_ratio < rare_threshold:\n",
    "        label_type = \"rare\"\n",
    "    else:\n",
    "        label_type = \"typical\"\n",
    "\n",
    "    return {\n",
    "        \"type\": label_type,\n",
    "        \"closest_cluster\": int(closest_cluster),\n",
    "        \"cluster_size_ratio\": round(cluster_ratio, 4),\n",
    "        \"distance_to_cluster_center\": round(closest_distance, 4),\n",
    "        \"abnormal_cutoff\": round(abnormal_cutoff, 4)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da3019-4ccd-4e29-942c-bd9d20796a00",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell37"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_anomaly_detector(test_listings, classify_func, top_features, scaler, X_scaled, cluster_labels):\n",
    "    \"\"\"\n",
    "    test_listings: list of dicts, each with input fields + LABEL\n",
    "    classify_func: function that outputs {type: \"typical\" / \"rare\" / \"anomaly\"}\n",
    "    top_features, scaler, X_scaled, cluster_labels: as used in classification\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for listing in test_listings:\n",
    "        label = listing.pop(\"LABEL\")  # extract true label\n",
    "        y_true.append(label)\n",
    "\n",
    "        try:\n",
    "            result = classify_func(\n",
    "                user_input_raw=listing,\n",
    "                top_features=top_features,\n",
    "                scaler=scaler,\n",
    "                X_scaled=X_scaled,\n",
    "                cluster_labels=cluster_labels\n",
    "            )\n",
    "            y_pred.append(result[\"type\"])\n",
    "        except Exception as e:\n",
    "            y_pred.append(\"error\")\n",
    "\n",
    "    # Report\n",
    "    labels_order = [\"typical\", \"rare\", \"anomaly\"]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels_order)\n",
    "    report = classification_report(y_true, y_pred, labels=labels_order, output_dict=True)\n",
    "\n",
    "    return {\n",
    "        \"confusion_matrix\": pd.DataFrame(cm, index=labels_order, columns=labels_order),\n",
    "        \"classification_report\": pd.DataFrame(report).T,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab7799-253e-449a-bc13-12f001b77694",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": [
    "# Generate 100 labeled test listings: 70 typical, 15 rare, 15 anomaly\n",
    "full_test_listings = []\n",
    "\n",
    "# Generate 70 typical\n",
    "for _ in range(350):\n",
    "    full_test_listings.append({\n",
    "        \"ROOM_TYPE\": \"Entire home/apt\",\n",
    "        \"PROPERTY_TYPE\": \"Apartment\",\n",
    "        \"ACCOMMODATES\": np.random.randint(2, 5),\n",
    "        \"BEDROOMS\": np.random.randint(1, 3),\n",
    "        \"BEDS\": np.random.randint(1, 4),\n",
    "        \"PRICE\": np.random.randint(80, 180),\n",
    "        \"AVAILABILITY_365\": np.random.randint(150, 365),\n",
    "        \"HOST_LISTINGS_COUNT\": np.random.randint(1, 3),\n",
    "        \"REVIEWS_PER_MONTH\": np.random.normal(1.0, 0.5),\n",
    "        \"LABEL\": \"typical\"\n",
    "    })\n",
    "\n",
    "# Generate 15 rare\n",
    "for _ in range(75):\n",
    "    full_test_listings.append({\n",
    "        \"ROOM_TYPE\": \"Shared room\",\n",
    "        \"PROPERTY_TYPE\": \"Hostel\",\n",
    "        \"ACCOMMODATES\": np.random.randint(3, 6),\n",
    "        \"BEDROOMS\": np.random.randint(1, 3),\n",
    "        \"BEDS\": np.random.randint(3, 5),\n",
    "        \"PRICE\": np.random.randint(20, 50),\n",
    "        \"AVAILABILITY_365\": 365,\n",
    "        \"HOST_LISTINGS_COUNT\": 1,\n",
    "        \"REVIEWS_PER_MONTH\": np.random.normal(0.5, 0.2),\n",
    "        \"LABEL\": \"rare\"\n",
    "    })\n",
    "\n",
    "# Generate 15 anomaly\n",
    "for _ in range(150):\n",
    "    full_test_listings.append({\n",
    "        \"ROOM_TYPE\": \"Private room\",\n",
    "        \"PROPERTY_TYPE\": \"Condominium\",\n",
    "        \"ACCOMMODATES\": np.random.randint(20, 30),\n",
    "        \"BEDROOMS\": 9,\n",
    "        \"BEDS\": 1,\n",
    "        \"PRICE\": 2000,\n",
    "        \"AVAILABILITY_365\": 30,\n",
    "        \"HOST_LISTINGS_COUNT\": np.random.randint(20, 50),\n",
    "        \"REVIEWS_PER_MONTH\": np.random.normal(0.1, 0.1),\n",
    "        \"LABEL\": \"anomaly\"\n",
    "    })\n",
    "\n",
    "# # Generate 70 typical\n",
    "# for _ in range(70):\n",
    "#     full_test_listings.append({\n",
    "#         \"ROOM_TYPE\": \"Entire home/apt\",\n",
    "#         \"PROPERTY_TYPE\": \"Apartment\",\n",
    "#         \"ACCOMMODATES\": np.random.randint(2, 6),\n",
    "#         \"BEDROOMS\": np.random.randint(1, 3),\n",
    "#         \"BEDS\": np.random.randint(1, 4),\n",
    "#         \"PRICE\": np.random.randint(80, 180),\n",
    "#         \"AVAILABILITY_365\": np.random.randint(150, 380),\n",
    "#         \"HOST_LISTINGS_COUNT\": np.random.randint(1, 3),\n",
    "#         \"REVIEWS_PER_MONTH\": np.random.normal(1.0, 0.6),\n",
    "#         \"LABEL\": \"typical\"\n",
    "#     })\n",
    "\n",
    "# # Generate 15 rare\n",
    "# for _ in range(15):\n",
    "#     full_test_listings.append({\n",
    "#         \"ROOM_TYPE\": \"Shared room\",\n",
    "#         \"PROPERTY_TYPE\": \"Hostel\",\n",
    "#         \"ACCOMMODATES\": np.random.randint(3, 5),\n",
    "#         \"BEDROOMS\": np.random.randint(1, 3),\n",
    "#         \"BEDS\": np.random.randint(4, 5),\n",
    "#         \"PRICE\": np.random.randint(20, 50),\n",
    "#         \"AVAILABILITY_365\": 360,\n",
    "#         \"HOST_LISTINGS_COUNT\": 1,\n",
    "#         \"REVIEWS_PER_MONTH\": np.random.normal(0.6, 0.2),\n",
    "#         \"LABEL\": \"rare\"\n",
    "#     })\n",
    "\n",
    "# # Generate 15 anomaly\n",
    "# for _ in range(15):\n",
    "#     full_test_listings.append({\n",
    "#         \"ROOM_TYPE\": \"Private room\",\n",
    "#         \"PROPERTY_TYPE\": \"Condominium\",\n",
    "#         \"ACCOMMODATES\": np.random.randint(1, 2),\n",
    "#         \"BEDROOMS\": np.random.randint(4, 10),\n",
    "#         \"BEDS\": np.random.randint(1, 2),\n",
    "#         \"PRICE\": np.random.randint(500, 2000),\n",
    "#         \"AVAILABILITY_365\": np.random.randint(1, 30),\n",
    "#         \"HOST_LISTINGS_COUNT\": np.random.randint(20, 50),\n",
    "#         \"REVIEWS_PER_MONTH\": np.random.normal(0.1, 0.1),\n",
    "#         \"LABEL\": \"anomaly\"\n",
    "#     })\n",
    "\n",
    "# Shuffle the list\n",
    "np.random.shuffle(full_test_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0377445-0b83-4fe0-9239-820fa63e1c1c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell40"
   },
   "outputs": [],
   "source": [
    "result = evaluate_anomaly_detector(\n",
    "    test_listings=full_test_listings,             # 你刚才生成的100条数据\n",
    "    classify_func=classify_listing_from_raw_input,  # 判定函数\n",
    "    top_features=top_features,                    # 你的最终特征名列表\n",
    "    scaler=scaler,                                # 标准化器\n",
    "    X_scaled=X_scaled,                            # 训练数据（已标准化）\n",
    "    cluster_labels=new_labels                     # DBSCAN 输出标签\n",
    ")\n",
    "result[\"confusion_matrix\"]         # 混淆矩阵（DataFrame）\n",
    "result[\"classification_report\"]   # precision / recall / f1-score\n",
    "result[\"y_true\"], result[\"y_pred\"] # 原始标签与预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f695ad7-cc8e-4d00-b810-eb843f0f1a0d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell41"
   },
   "outputs": [],
   "source": [
    "import joblib, json, numpy as np\n",
    "\n",
    "# 1) 模型工件\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "with open('top_features.json', 'w') as f:\n",
    "    json.dump(top_features, f)\n",
    "np.save('X_scaled.npy', X_scaled)\n",
    "np.save('cluster_labels.npy', np.array(new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46ef6d-ef95-4bb3-8aae-439637a9d436",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell42"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 列出当前目录所有文件\n",
    "print(os.listdir(\".\"))\n",
    "\n",
    "# 如果要下载某个文件到本地\n",
    "import snowflake.snowpark as snowpark  # 如果支持\n",
    "# 或者直接 Notebook 提供的 download 工具按钮\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cfc1f-8c08-486a-9a94-bd77efbb753d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# 把要下载的文件都加进来\n",
    "with zipfile.ZipFile(\"artifacts.zip\", \"w\") as zf:\n",
    "    zf.write(\"scaler.pkl\")\n",
    "    zf.write(\"top_features.json\")\n",
    "    zf.write(\"X_scaled.npy\")\n",
    "    zf.write(\"cluster_labels.npy\")\n",
    "    # 如果你有 full_test_listings.json 也可以加进来\n",
    "    # zf.write(\"full_test_listings.json\")\n",
    "\n",
    "print(\"打包完成: artifacts.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b212e34-aa6e-4815-ba3f-6cb46f8e5481",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def create_download_link(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    b64 = base64.b64encode(data).decode()\n",
    "    return HTML(f'<a href=\"data:application/zip;base64,{b64}\" download=\"{filename}\">下载 {filename}</a>')\n",
    "\n",
    "display(create_download_link(\"artifacts.zip\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d69b5-8ee6-4889-ab90-2068c2537691",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell38"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "jasondai1219@gmail.com",
   "authorId": "6387745362132",
   "authorName": "JASONDAI1219",
   "lastEditTime": 1754820132748,
   "notebookId": "fe4d5idjh542zrlh4gq7",
   "sessionId": "3a4b55b1-d5f9-4c25-8efb-14fc035ac710"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
